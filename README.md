
# Асинхронный парсер документов PEP

Парсер документов PEP на базе фреймворка Scrapy. Парсер должен выводить собранную информацию в два файла .csv:

* В первый файл выводится список всех PEP: номер, название и статус.
* Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество). В последней строке этого файла в колонке «Статус» стоит слово Total, а в колонке «Количество» — общее количество всех документов. 

###  Установка и настройки
  * Шаг первый: клонируем репозиторий
```python
git clone git@github.com:Nurbek878/scrapy_parser_pep.git
```
 * Переходим в папку с проектом 
```sh 
cd scrapy_parser_pep
``` 
* Создаем и активируем виртуальное окружение 
```sh 
python -m venv venv 
source venv/bin/activate 
``` 
* Обновляем менеджер пакетов pip
```sh 
pip install --upgrade pip 
``` 
* Устанавливаем необходимые зависимости 
```sh 
pip install -r requirements.txt
``` 
* Запускаем парсер 
```sh 
scrapy crawl pep
``` 

### Стек
-   [Python](https://www.python.org/)
-   [Scrapy](https://scrapy.org/)


##### Автор

- [@nurbek878](https://github.com/Nurbek878)
